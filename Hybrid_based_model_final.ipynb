{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26xLVnYU1Jr",
        "outputId": "a1851132-9300-4a34-a257-a61960c2e598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-035932fe4a95>:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  users_df.fillna(\"\", inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6863\n",
            "Recall: 1.0000\n",
            "F1-score: 0.8140\n",
            "Recommended Places: ['North Coast', 'Alexandria', 'Ain El Sokhna', 'Taba', 'Marsa Matrouh']\n",
            "Most Similar Users (Indices): [73 53 81 49 64]\n",
            "Similarity Scores: [0.60279906 0.48298573 0.41040023 0.39483433 0.38372469]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Load datasets\n",
        "users_df = pd.read_excel(\"Users.xlsx\")\n",
        "places_df = pd.read_excel(\"Places.xlsx\")\n",
        "\n",
        "# Define category columns\n",
        "category_columns = [\n",
        "    \"Historical Sites\", \"Beaches\", \"Adventure\", \"Nile Cruises\",\n",
        "    \"Religious Tourism\", \"Desert Exploration\", \"Relaxation\"\n",
        "]\n",
        "\n",
        "# Ensure category columns are numeric\n",
        "places_df[category_columns] = places_df[category_columns].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Create 'combined_info' column for each place\n",
        "places_df['combined_info'] = places_df[category_columns].apply(lambda row: ' '.join(row.index[row == 1]), axis=1)\n",
        "\n",
        "# Merge place categories into users_df\n",
        "users_df = users_df.merge(places_df[['Place name', 'combined_info'] + category_columns],\n",
        "                          left_on='Preferred Places', right_on='Place name', how='left')\n",
        "users_df.fillna(\"\", inplace=True)\n",
        "\n",
        "# Aggregate category values when users have multiple preferred places\n",
        "users_df = users_df.groupby(['User ID', 'Age', 'Gender', 'Marital status', 'Children', 'Travel Tags']) \\\n",
        "    .agg({\n",
        "        'Preferred Places': lambda x: ', '.join(x),\n",
        "        'combined_info': lambda x: ' '.join(x),\n",
        "        **{col: 'max' for col in category_columns}  # Take max value for category presence\n",
        "    }).reset_index()\n",
        "\n",
        "# Combine user features for TF-IDF\n",
        "users_df['combined_features'] = (\n",
        "    users_df['Preferred Places'] + \" \" + users_df['Travel Tags'] + \" \" +\n",
        "    users_df['Age'].astype(str) + \" \" + users_df['Marital status'] + \" \" +\n",
        "    users_df['Children'] + \" \" + users_df['Gender'] + \" \" + users_df['combined_info']\n",
        ")\n",
        "\n",
        "# Train-test split (BEFORE TF-IDF processing)\n",
        "train_df, test_df = train_test_split(users_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization (fit on train, transform on both train and test)\n",
        "tf = TfidfVectorizer(stop_words='english', use_idf=False)\n",
        "tf_matrix_train = tf.fit_transform(train_df['combined_features'])\n",
        "tf_matrix_test = tf.transform(test_df['combined_features'])\n",
        "\n",
        "# Define feature weights\n",
        "weights = {\n",
        "    'Preferred Places': 6,\n",
        "    'Travel Tags': 4,\n",
        "    'Age': 1,\n",
        "    'Marital status': 1,\n",
        "    'Children': 1,\n",
        "    'Gender': 1,\n",
        "    'combined_info': 5\n",
        "}\n",
        "\n",
        "# Create weight vector based on TF-IDF features\n",
        "feature_names = tf.get_feature_names_out()\n",
        "weight_vector = np.ones(len(feature_names))\n",
        "\n",
        "for i, feature in enumerate(feature_names):\n",
        "    if any(word in feature for word in train_df['Preferred Places'].str.lower().str.split().explode().unique()):\n",
        "        weight_vector[i] = weights['Preferred Places']\n",
        "    elif any(word in feature for word in train_df['Travel Tags'].str.lower().str.split().explode().unique()):\n",
        "        weight_vector[i] = weights['Travel Tags']\n",
        "    elif any(str(word) in feature for word in train_df['Age'].unique()):\n",
        "        weight_vector[i] = weights['Age']\n",
        "    elif any(word in feature for word in train_df['Marital status'].str.lower().unique()):\n",
        "        weight_vector[i] = weights['Marital status']\n",
        "    elif any(word in feature for word in train_df['Children'].str.lower().unique()):\n",
        "        weight_vector[i] = weights['Children']\n",
        "    elif any(word in feature for word in train_df['Gender'].str.lower().unique()):\n",
        "        weight_vector[i] = weights['Gender']\n",
        "    elif any(str(word) in feature for word in train_df['combined_info'].dropna().astype(str).str.lower().str.split().explode().unique()):\n",
        "        weight_vector[i] = weights['combined_info']\n",
        "\n",
        "# Apply weights\n",
        "weighted_tfidf_matrix_train = tf_matrix_train.multiply(weight_vector).toarray()\n",
        "weighted_tfidf_matrix_test = tf_matrix_test.multiply(weight_vector).toarray()\n",
        "\n",
        "# Compute similarity matrix for training set\n",
        "cosine_sim_train = np.array(\n",
        "    Parallel(n_jobs=-1)(delayed(lambda i: cosine_similarity([weighted_tfidf_matrix_train[i]], weighted_tfidf_matrix_train).flatten())(i)\n",
        "                         for i in range(weighted_tfidf_matrix_train.shape[0]))\n",
        ")\n",
        "\n",
        "# Function to recommend places\n",
        "def recommend_places(new_user_preferences, train_df, weighted_tfidf_matrix_train, top_n=5):\n",
        "    new_user_data = new_user_preferences.split(\", \")\n",
        "    visited_places = set(new_user_data[:1])\n",
        "\n",
        "    new_user_tf = tf.transform([\" \".join(new_user_data)])\n",
        "    weighted_new_user_tf = new_user_tf.multiply(weight_vector).toarray()\n",
        "    sim_scores = cosine_similarity(weighted_new_user_tf, weighted_tfidf_matrix_train).flatten()\n",
        "\n",
        "    most_similar_users_indices = sim_scores.argsort()[-top_n:][::-1]\n",
        "\n",
        "    place_counts = {}\n",
        "    for user_idx in most_similar_users_indices:\n",
        "        if user_idx < len(train_df):\n",
        "            places = train_df.iloc[user_idx]['Preferred Places'].split(\", \")\n",
        "            for place in places:\n",
        "                if place not in visited_places:\n",
        "                    place_counts[place] = place_counts.get(place, 0) + 1\n",
        "\n",
        "    sorted_places = sorted(place_counts, key=place_counts.get, reverse=True)\n",
        "\n",
        "    return sorted_places[:top_n], most_similar_users_indices, sim_scores[most_similar_users_indices]\n",
        "\n",
        "# Evaluate model\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "    actual_places = set(row['Preferred Places'].split(\", \"))\n",
        "    recommended_places, _, _ = recommend_places(row['combined_features'], train_df, weighted_tfidf_matrix_train)\n",
        "    y_true.extend([1 if place in actual_places else 0 for place in recommended_places])\n",
        "    y_pred.extend([1] * len(recommended_places))\n",
        "\n",
        "precision = precision_score(y_true, y_pred) if y_pred else 0\n",
        "recall = recall_score(y_true, y_pred) if y_pred else 0\n",
        "f1 = f1_score(y_true, y_pred) if y_pred else 0\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "new_user_preferences = \"Dahab, Desert Exploration, Adventure, 25, Single, No, Female\"\n",
        "recommended_places, similar_users, similarity_scores = recommend_places(new_user_preferences, train_df, weighted_tfidf_matrix_train)\n",
        "\n",
        "print(\"Recommended Places:\", recommended_places)\n",
        "print(\"Most Similar Users (Indices):\", similar_users)\n",
        "print(\"Similarity Scores:\", similarity_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save artifacts\n",
        "joblib.dump(tf, \"tfidf_vectorizer.pkl\")\n",
        "np.save(\"weight_vector.npy\", weight_vector)\n",
        "joblib.dump(train_df, \"train_df.pkl\")\n",
        "np.save(\"tfidf_matrix_train.npy\", weighted_tfidf_matrix_train)\n"
      ],
      "metadata": {
        "id": "wnibUNl_6qHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}